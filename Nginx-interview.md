[TOC]

# Nginx 面试题

<https://zhuanlan.zhihu.com/p/101907416?hmsr=toutiao.io>

## 1、什么是Nginx

Nginx是一个高性能的反向代理服务器，他是一个非常高效的反向代理、负载平衡，他可以处理2-3万并发连接数，官方监测能支持5万并发

## 2、为什么要用Nginx

跨平台、配置简单、方向代理、高并发连接：处理2-3万并发连接数，官方监测能支持5万并发，内存消耗小：开启10个nginx才占150M内存 ，nginx处理静态文件好，耗费内存少，

而且Nginx内置的健康检查功能：如果有一个服务器宕机，会做一个健康检查，再发送的请求就不会发送到宕机的服务器了。重新将请求提交到其他的节点上。

使用Nginx的话还能：

节省宽带：支持GZIP压缩，可以添加浏览器本地缓存

稳定性高：宕机的概率非常小

接收用户请求是异步的

**3、为什么Nginx性能这么高**

因为他的事件处理机制：异步非阻塞事件处理机制：运用了epoll模型，提供了一个队列，排队解决

**4.Nginx怎么处理请求的**

nginx接收一个请求后，首先由listen和server_name指令匹配server模块，再匹配server模块里的location，location就是实际地址

**5.什么是正向代理和反向代理**

1、正向代理就是一个人发送一个请求直接就到达了目标的服务器

2、反方代理就是请求统一被Nginx接收，nginx反向代理服务器接收到之后，按照一定的规则分发给了后端的业务处理服务器进行处理了

**6.使用“反向代理服务器的优点是什么?**

反向代理服务器可以隐藏源服务器的存在和特征。它充当互联网云和web服务器之间的中间层。这对于安全方面来说是很好的，特别是当您使用web托管服务时。

**7.Nginx的优缺点**

优点：

1.占内存小，可实现高并发连接，处理响应快

2.可实现http服务器、虚拟主机、方向代理、负载均衡

3.Nginx配置简单

4.可以不暴露正式的服务器IP地址

缺点：

动态处理差：nginx处理静态文件好,耗费内存少，但是处理动态页面则很鸡肋，现在一般前端用nginx作为反向代理抗住压力，

**8.如何用Nginx解决前端跨域问题？**

使用Nginx转发请求。把跨域的接口写成调本域的接口，然后将这些接口转发到真正的请求地址。

**9 .限流怎么做的，算法是什么，（限制请求速度）**

Nginx限流就是限制用户请求速度，防止服务器受不了

限流有3种，我这只写了最平常的一种（限制访问频率（正常流量））

1、限制访问频率（正常流量）

2、限制访问频率（突发流量）

3、限制并发连接数

1、限制访问频率（正常流量）：限制一个用户发送的请求，我Nginx多久接收一个。

\#定义限流维度，一个用户一分钟一个请求进来，多余的全部漏掉

1. limit_req_zone $binary_remote_addr zone=one:10m rate=1r/m;
2. \#绑定限流维度
3. server{
4. location/seckill.html{
5. limit_req zone=one
6. proxy_pass [http://lj_seckill](https://link.zhihu.com/?target=http%3A//lj_seckill);
7. }
8. }

1r/s代表1秒一个请求1r/m一分钟接收一个请求

（此流也叫做漏桶流，多余的请求全部不要，漏掉）

**10.为什么要做动静分离?**

Nginx是当下最热的Web容器，网站优化的重要点在于静态化网站，网站静态化的关键点则是是动静分离，动静分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后，我们则根据静态资源的特点将其做缓存操作。

让静态的资源只走静态资源服务器，动态的走动态的服务器

Nginx的静态处理能力很强，但是动态处理能力不足，因此，在企业中常用动静分离技术。

对于静态资源比如图片，js，css等文件，我们则在反向代理服务器nginx中进行缓存。这样浏览器在请求一个静态资源时，代理服务器nginx就可以直接处理，无需将请求转发给后端服务器tomcat。

若用户请求的动态文件，比如servlet,jsp则转发给Tomcat服务器处理，从而实现动静分离。这也是反向代理服务器的一个重要的作用。

**11.怎么做的动静分离**

只需要指定路径对应的目录。location/可以使用正则表达式匹配。并指定对应的硬盘中的目录。如下：（操作都是在Linux上）

1. location /image/ {
2. root /usr/local/static/;
3. autoindex on;
4. }

1、创建目录

mkdir /usr/local/static/image

2、进入目录

cd /usr/local/static/image

3、放一张照片上去#

ls

1.jpg

4、重启 nginx

sudo nginx -s reload

5、打开浏览器 输入 server_name/image/1.jpg 就可以访问该静态图片了

**12、Nginx负载均衡的算法怎么实现的?策略有哪些?**

为了避免服务器崩溃，大家会通过负载均衡的方式来分担服务器压力。将对台服务器组成一个集群，当用户访问时，先访问到一个转发服务器，再由转发服务器将访问分发到压力更小的服务器。

Nginx负载均衡实现的策略有以下五种：

(1) 轮询(默认)

每个请求按时间顺序逐一分配到不同的后端服务器，如果后端某个服务器宕机，能自动剔除故障系统。

1. upstream backserver {
2. server 192.168.0.12;
3. server 192.168.0.13;
4. }

(2) 权重 weight

weight的值越大分配到的访问概率越高，主要用于后端每台服务器性能不均衡的情况下。其次是为在主从的情况下设置不同的权值，达到合理有效的地利用主机资源。

1. upstream backserver {
2. server 192.168.0.12 weight=2;
3. server 192.168.0.13 weight=8;
4. }

权重越高，在被访问的概率越大，如上例，分别是20%，80%。

(3) ip_hash( IP绑定)

每个请求按访问IP的哈希结果分配，使来自同一个IP的访客固定访问一台后端服务器，并且可以有效解决动态网页存在的session共享问题

1. upstream backserver {
2. ip_hash;
3. server 192.168.0.12:88;
4. server 192.168.0.13:80;
5. }

(4) fair(第三方插件)

必须安装upstream_fair模块。

对比 weight、ip_hash更加智能的负载均衡算法，fair算法可以根据页面大小和加载时间长短智能地进行负载均衡，响应时间短的优先分配。

1. upstream backserver {
2. server server1;
3. server server2;
4. fair;
5. }

哪个服务器的响应速度快，就将请求分配到那个服务器上。

(5) url_hash(第三方插件)

必须安装Nginx的hash软件包

按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，可以进一步提高后端缓存服务器的效率。

1. upstream backserver {
2. server squid1:3128;
3. server squid2:3128;
4. hash $request_uri;
5. hash_method crc32;
6. }

https://segmentfault.com/a/1190000010677483



## 1、请解释一下什么是`Nginx`?

Nginx是一个web服务器和反向代理服务器，用于`HTTP`、`HTTPS`、`SMTP`、`POP3`和`IMAP`协议。

## 2、请列举`Nginx`的一些特性。

`Nginx`服务器的特性包括：

反向代理/L7负载均衡器

嵌入式Perl解释器

动态二进制升级

可用于重新编写URL，具有非常好的PCRE支持

3、请列举`Nginx`和`Apache` 之间的不同点。

## ![图片描述](https://segmentfault.com/img/bVSXRa?w=640&h=367)

## 4、请解释`Nginx`如何处理`HTTP`请求。

`Nginx`使用反应器模式。主事件循环等待操作系统发出准备事件的信号，这样数据就可以从套接字读取，在该实例中读取到缓冲区并进行处理。单个线程可以提供数万个并发连接。

## 5、在`Nginx`中，如何使用未定义的服务器名称来阻止处理请求?

只需将请求删除的服务器就可以定义为：

```
Server {

listen 80;

server_name “ “ ;

return 444;

}
```

这里，服务器名被保留为一个空字符串，它将在没有“主机”头字段的情况下匹配请求，而一个特殊的`Nginx`的非标准代码`444`被返回，从而终止连接。

## 6、 使用“反向代理服务器”的优点是什么?

反向代理服务器可以隐藏源服务器的存在和特征。它充当互联网云和web服务器之间的中间层。这对于安全方面来说是很好的，特别是当您使用web托管服务时。

## 7、请列举`Nginx`服务器的最佳用途。

`Nginx`服务器的最佳用法是在网络上部署动态`HTTP`内容，使用`SCGI`、`WSGI`应用程序服务器、用于脚本的`FastCGI`处理程序。它还可以作为负载均衡器。

## 8、请解释`Nginx`服务器上的`Master`和`Worker`进程分别是什么?

`Master`进程：读取及评估配置和维持

`Worker`进程：处理请求

## 9、请解释你如何通过不同于80的端口开启Nginx?

为了通过一个不同的端口开启`Nginx`，你必须进入`/etc/Nginx/sites-enabled/`，如果这是默认文件，那么你必须打开名为`“default”`的文件。编辑文件，并放置在你想要的端口：

```
Like server { listen 81; }
```

## 10、请解释是否有可能将`Nginx`的错误替换为`502`错误、`503`?

`502` =错误网关

`503` =服务器超载

有可能，但是您可以确保`fastcgi_intercept_errors`被设置为`ON`，并使用错误页面指令。

```
Location / {
fastcgi_pass 127.0.01:9001;
fastcgi_intercept_errors on;
error_page 502 =503/error_page.html;
#…
}
```

## 11、在`Nginx`中，解释如何在`URL`中保留双斜线?

要在`URL`中保留双斜线，就必须使用`merge_slashes_off`;

语法:`merge_slashes [on/off]`

默认值: `merge_slashes on`

环境: `http，server`

## 12、请解释`ngx_http_upstream_module`的作用是什么?

`ngx_http_upstream_module`用于定义可通过`fastcgi`传递、`proxy`传递、`uwsgi`传递、`memcached`传递和scgi传递指令来引用的服务器组。

## 13、请解释什么是`C10K`问题?

`C10K`问题是指无法同时处理大量客户端(10,000)的网络套接字。

## 14、请陈述`stub_status`和`sub_filter`指令的作用是什么?

`Stub_status`指令：该指令用于了解`Nginx`当前状态的当前状态，如当前的活动连接，接受和处理当前读/写/等待连接的总数

`Sub_filter`指令：它用于搜索和替换响应中的内容，并快速修复陈旧的数据

## 15、解释`Nginx`是否支持将请求压缩到上游?

您可以使用`Nginx`模块`gunzip`将请求压缩到上游。`gunzip`模块是一个过滤器，它可以对不支持“gzip”编码方法的客户机或服务器使用“内容编码:gzip”来解压缩响应。

## 16、解释如何在`Nginx`中获得当前的时间?

要获得Nginx的当前时间，必须使用`SSI`模块、`$date_gmt`和`$date_local`的变量。

`Proxy_set_header` `THE-TIME $date_gmt`;

## 17、用`Nginx`服务器解释`-s`的目的是什么?

用于运行`Nginx -s`参数的可执行文件。

## 18、解释如何在`Nginx`服务器上添加模块?

在编译过程中，必须选择`Nginx`模块，因为`Nginx`不支持模块的运行时间选择。



<https://blog.csdn.net/Yang_Hui_Liang/article/details/90263906>

## 1、什么是Nginx

Nginx是一个高性能的HTTP和反向代理服务器，及电子邮件代理服务器，同时也是一个非常高效的反向代理、负载平衡。

##  

## 2、为什么要用Nginx

跨平台、配置简单，非阻塞、高并发连接：处理2-3万并发连接数，官方监测能支持5万并发，

**内存消耗小：**开启10个nginx才占150M内存 ，nginx处理静态文件好,耗费内存少,

**内置的健康检查功能**：如果有一个服务器宕机，会做一个健康检查，再发送的请求就不会发送到宕机的服务器了。重新将请求提交到其他的节点上。

**节省宽带**：支持GZIP压缩，可以添加浏览器本地缓存

**稳定性高**：宕机的概率非常小

**接收用户请求是异步的**：浏览器将请求发送到nginx服务器，它先将用户请求全部接收下来，再一次性发送给后端web服务器，极大减轻了web服务器的压力,一边接收web服务器的返回数据，一边发送给浏览器客户端, 网络依赖性比较低，只要ping通就可以负载均衡,可以有多台nginx服务器 使用dns做负载均衡,事件驱动：通信机制采用epoll模型（nio2 异步非阻塞）

##  

## 3、为什么Nginx性能这么高

得益于它的事件处理机制：异步非阻塞事件处理机制：运用了epoll模型，提供了一个队列，排队解决
    

## 4、Nginx是如何处理一个请求的

首先，nginx在启动时，会解析配置文件，得到需要监听的端口与ip地址，然后在nginx的master进程里面先初始化好这个监控的socket，再进行listen,然后再fork出多个子进程出来,  子进程会竞争accept新的连接。此时，客户端就可以向nginx发起连接了。当客户端与nginx进行三次握手，与nginx建立好一个连接后,此时，某一个子进程会accept成功，然后创建nginx对连接的封装，即ngx_connection_t结构体,接着，根据事件调用相应的事件处理模块，如http模块与客户端进行数据的交换。最后，nginx或客户端来主动关掉连接，到此，一个连接就寿终正寝了

 

## 5、正向代理

 一个位于客户端和原始服务器之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端才能使用正向代理

正向代理总结就一句话：代理端代理的是客户端


## 6、反向代理

反向代理是指以代理服务器来接受internet上的连接请求，然后将请求，发给内部网络上的服务器,并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器

反向代理总结就一句话：代理端代理的是服务端

 

## 7、动态资源、静态资源分离

动态资源、静态资源分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后，我们就可以根据静态资源的特点将其做缓存操作，这就是网站静态化处理的核心思路,动态资源、静态资源分离简单的概括是：动态文件与静态文件的分离


## 8、为什么要做动、静分离

在我们的软件开发中，有些请求是需要后台处理的（如：.jsp,.do等等），有些请求是不需要经过后台处理的（如：css、html、jpg、js等等文件）,这些不需要经过后台处理的文件称为静态文件，因此我们后台处理忽略静态文件。这会有人又说那我后台忽略静态文件不就完了吗,当然这是可以的，但是这样后台的请求次数就明显增多了。在我们对资源的响应速度有要求的时候，我们应该使用这种动静分离的策略去解决，动、静分离将网站静态资源（HTML，JavaScript，CSS，img等文件）与后台应用分开部署，提高用户访问静态代码的速度，降低对后台应用访问，这里我们将静态资源放到nginx中，动态资源转发到tomcat服务器中

 

## 9、负载均衡

负载均衡即是代理服务器将接收的请求均衡的分发到各服务器中，负载均衡主要解决网络拥塞问题，提高服务器响应速度，服务就近提供，达到更好的访问质量，减少后台服务器大并发压力



<https://blog.csdn.net/a303549861/article/details/88672901>

##### **1.请解释一下什么是 Nginx ？**

```nginx
Nginx ，是一个 Web 服务器和反向代理服务器，用于 HTTP、HTTPS、SMTP、POP3 和 IMAP 协议。
目前使用的最多的 Web 服务器或者代理服务器，像淘宝、新浪、网易、迅雷等都在使用。
Nginx 的主要功能如下：
作为 http server (代替 Apache ，对 PHP 需要 FastCGI 处理器支持)
FastCGI：Nginx 本身不支持 PHP 等语言，但是它可以通过 FastCGI 来将请求扔给某些语言或框架处理。
反向代理服务器
实现负载均衡
虚拟主机
12345678
```

##### **2.fastcgi 与 cgi 的区别？**

1）cgi

> web 服务器会根据请求的内容，然后会 fork 一个新进程来运行外部 c 程序（或 perl 脚本…）， 这个进程会把处理完的数据返回给 web 服务器，最后 web 服务器把内容发送给用户，刚才 fork 的进程也随之退出。
>
> 如果下次用户还请求改动态脚本，那么 web 服务器又再次 fork 一个新进程，周而复始的进行。

2）fastcgi

> web 服务器收到一个请求时，他不会重新 fork 一个进程（因为这个进程在 web 服务器启动时就开启了，而且不会退出），web 服务器直接把内容传递给这个进程（进程间通信，但 fastcgi 使用了别的方式，tcp 方式通信），这个进程收到请求后进行处理，把结果返回给 web 服务器，最后自己接着等待下一个请求的到来，而不是退出。

? 综上，差别在于是否重复 fork 进程，处理请求。

##### 3.Nginx 常用命令？

- 启动 `nginx` 。
- 停止 `nginx -s stop` 或 `nginx -s quit` 。
- 重载配置 `./sbin/nginx -s reload(平滑重启)` 或 `service nginx reload` 。
- 重载指定配置文件 `.nginx -c /usr/local/nginx/conf/nginx.conf` 。
- 查看 nginx 版本 `nginx -v` 。
- 检查配置文件是否正确 `nginx -t` 。
- 显示帮助信息 `nginx -h` 。

##### 4.Nginx 常用配置？

```nginx
worker_processes  8; # 工作进程个数
worker_connections  65535; # 每个工作进程能并发处理（发起）的最大连接数（包含所有连接数）
error_log         /data/logs/nginx/error.log; # 错误日志打印地址
access_log      /data/logs/nginx/access.log; # 进入日志打印地址
log_format  main  '$remote_addr"$request" ''$status $upstream_addr "$request_time"'; # 进入日志格式

## 如果未使用 fastcgi 功能的，可以无视
fastcgi_connect_timeout=300; # 连接到后端 fastcgi 超时时间
fastcgi_send_timeout=300; # 向 fastcgi 请求超时时间(这个指定值已经完成两次握手后向fastcgi传送请求的超时时间)
fastcgi_rend_timeout=300; # 接收 fastcgi 应答超时时间，同理也是2次握手后
fastcgi_buffer_size=64k; # 读取 fastcgi 应答第一部分需要多大缓冲区，该值表示使用1个64kb的缓冲区读取应答第一部分(应答头),可以设置为fastcgi_buffers选项缓冲区大小
fastcgi_buffers 4 64k; # 指定本地需要多少和多大的缓冲区来缓冲fastcgi应答请求，假设一个php或java脚本所产生页面大小为256kb,那么会为其分配4个64kb的缓冲来缓存
fastcgi_cache TEST; # 开启fastcgi缓存并为其指定为TEST名称，降低cpu负载,防止502错误发生

listen       80; # 监听端口
server_name  rrc.test.jiedaibao.com; # 允许域名
root  /data/release/rrc/web; # 项目根目录
index  index.php index.html index.htm; # 访问根文件
123456789101112131415161718
```

? **Nginx 日志格式中的 $time_local 表示的是什么时间？请求开始的时间？请求结束的时间？其次，当我们从前到后观察日志中的 $time_local 时间时，有时候会发现时间顺序前后错乱的现象，请说明原因？**

`$time_local` ：在服务器里请求开始写入本地的时间。

因为请求发生时间有前有后，所以会时间顺序前后错乱。

##### 5.Nginx 有哪些优点？

- 跨平台、配置简单。

- 非阻塞、高并发连接

  > 处理 2-3 万并发连接数，官方监测能支持 5 万并发。

- 内存消耗小

  > 开启 10 个 Nginx 才占 150M 内存。

- 成本低廉，且开源。

- 稳定性高，宕机的概率非常小。

##### 6.使用“反向代理服务器”的优点是什么？

反向代理服务器可以隐藏源服务器的存在和特征。它充当互联网云和 Web 服务器之间的中间层。这对于安全方面来说是很好的，特别是当我们使用 Web 托管服务时。

> 这里，先不考虑负载均衡。

? **什么是正向代理？**

一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。

- 客户端才能使用正向代理。
- 正向代理总结就一句话：代理端代理的是客户端。例如说：? 我们使用的翻墙软件，OpenVPN 等等。

? **什么是反向代理？**

反向代理（Reverse Proxy）方式，是指以代理服务器来接受 Internet上的连接请求，然后将请求，发给内部网络上的服务器并将从服务器上得到的结果返回给 Internet 上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。

反向代理总结就一句话：代理端代理的是服务端。

? **请列举 Nginx 和 Apache 之间的不同点？**

![code](http://static.iocoder.cn/7bdf14ce3d607e5765e37750cc49d65f)

- 轻量级，同样起 web 服务，Nginx 比 Apache 占用更少的内存及资源。
- 抗并发，Nginx 处理请求是异步非阻塞的，而 Apache 则是阻塞型的，在高并发下 Nginx 能保持低资源低消耗高性能。
- 最核心的区别在于 Apache 是同步多进程模型，一个连接对应一个进程；Nginx 是异步的，多个连接（万级别）可以对应一个进程。
- Nginx 高度模块化的设计，编写模块相对简单。

**LVS、Nginx、HAproxy 有什么区别？**

- LVS ：是基于四层的转发。

- HAproxy ： 是基于四层和七层的转发，是专业的代理服务器。

- Nginx ：是 WEB 服务器，缓存服务器，又是反向代理服务器，可以做七层的转发。

  > Nginx 引入 [TCP 插件](https://docs.nginx.com/nginx/admin-guide/load-balancer/tcp-udp-load-balancer/)之后，也可以支持四层的转发。

? 区别

LVS 由于是基于四层的转发所以只能做端口的转发，而基于 URL 的、基于目录的这种转发 LVS 就做不了。

? 工作选择：

HAproxy 和 Nginx 由于可以做七层的转发，所以 URL 和目录的转发都可以做，在很大并发量的时候我们就要选择 LVS ，像中小型公司的话并发量没那么大选择 HAproxy 或者 Nginx 足已。

由于 HAproxy 由是专业的代理服务器配置简单，所以中小型企业推荐使用HAproxy 。

> 有些使用，使用 HAproxy 还是 Nginx ，也和公司运维对哪个技术栈的掌控程度。掌控 OK ，选择 Nginx 会更加不错。
>
> 另外，LVS + Nginx 和 LVS + HAProxy 也是比较常见的选型组合。

**Squid、Varinsh、Nginx 有什么区别？**

三者都实现缓存服务器的作用。所以，本问题所有的视角，都是在作为缓存服务器下来聊。

- 1、Nginx本来是反向代理/web服务器，用了插件可以做做这个副业(缓存服务器)。

  > 但是本身不支持特性挺多，只能缓存静态文件。

- 2、从这些功能上，Varinsh 和 Squid 是专业的 Cache 服务，而Nginx 这些是第三方模块完成。

- 3、Varnish 本身的技术上优势要高于 Squid ，它采用了可视化页面缓存技术。

  > - 在内存的利用上，Varnis h比 Squid 具有优势，性能要比 Squid 高。
  > - 还有强大的通过 Varnish 管理端口，可以使用正则表达式快速、批量地清除部分缓存
  > - Varnish 是内存缓存，速度一流，但是内存缓存也限制了其容量，缓存页面和图片一般是挺好的。

- 4、Squid 的优势在于完整的庞大的 cache 技术资料，和很多的应用生产环境。

? 工作选择：

要做 cache 服务的话，我们肯定是要选择专业的 cache 服务，优先选择Squid 或者 Varnish 。

## 请解释 Nginx 如何处理 HTTP 请求？

- 首先，Nginx 在启动时，会解析配置文件，得到需要监听的端口与 IP 地址，然后在 Nginx 的 Master 进程里面先初始化好这个监控的Socket(创建 S ocket，设置 addr、reuse 等选项，绑定到指定的 ip 地址端口，再 listen 监听)。

- 然后，再 fork(一个现有进程可以调用 fork 函数创建一个新进程。由 fork 创建的新进程被称为子进程 )出多个子进程出来。

- 之后，子进程会竞争 accept 新的连接。此时，客户端就可以向 nginx 发起连接了。当客户端与nginx进行三次握手，与 nginx 建立好一个连接后。此时，某一个子进程会 accept 成功，得到这个建立好的连接的 Socket ，然后创建 nginx 对连接的封装，即 ngx_connection_t 结构体。

- 接着，设置读写事件处理函数，并添加读写事件来与客户端进行数据的交换。

  > 这里，还是有一些逻辑，继续在 [「Nginx 是如何实现高并发的？」](http://svip.iocoder.cn/Nginx/Interview/#) 问题中来看。

- 最后，Nginx 或客户端来主动关掉连接，到此，一个连接就寿终正寝了。

- 最后，Nginx 或客户端来主动关掉连接，到此，一个连接就寿终正寝了。

? **Nginx 是如何实现高并发的？**

如果一个 server 采用一个进程(或者线程)负责一个request的方式，那么进程数就是并发数。那么显而易见的，就是会有很多进程在等待中。等什么？最多的应该是等待网络传输。其缺点胖友应该也感觉到了，此处不述。

> 思考下，Java 的 NIO 和 BIO 的对比哟。

而 Nginx 的异步非阻塞工作方式正是利用了这点等待的时间。在需要等待的时候，这些进程就空闲出来待命了。因此表现为少数几个进程就解决了大量的并发问题。

Nginx是如何利用的呢，简单来说：同样的 4 个进程，如果采用一个进程负责一个 request 的方式，那么，同时进来 4 个 request 之后，每个进程就负责其中一个，直至会话关闭。期间，如果有第 5 个request进来了。就无法及时反应了，因为 4 个进程都没干完活呢，因此，一般有个调度进程，每当新进来了一个 request ，就新开个进程来处理。

> 回想下，BIO 是不是存在酱紫的问题？嘻嘻。

Nginx 不这样，每进来一个 request ，会有一个 worker 进程去处理。但不是全程的处理，处理到什么程度呢？处理到可能发生阻塞的地方，比如向上游（后端）服务器转发 request ，并等待请求返回。那么，这个处理的 worker 不会这么傻等着，他会在发送完请求后，注册一个事件：“如果 upstream 返回了，告诉我一声，我再接着干”。于是他就休息去了。此时，如果再有 request 进来，他就可以很快再按这种方式处理。而一旦上游服务器返回了，就会触发这个事件，worker 才会来接手，这个 request 才会接着往下走。

> 这就是为什么说，Nginx 基于事件模型。

由于 web server 的工作性质决定了每个 request 的大部份生命都是在网络传输中，实际上花费在 server 机器上的时间片不多。这是几个进程就解决高并发的秘密所在。即：

> webserver 刚好属于网络 IO 密集型应用，不算是计算密集型。

而正如叔度所说的

> 异步，非阻塞，使用 epoll ，和大量细节处的优化。

也正是 Nginx 之所以然的技术基石。

**为什么 Nginx 不使用多线程？**

Apache: 创建多个进程或线程，而每个进程或线程都会为其分配 cpu 和内存（线程要比进程小的多，所以 worker 支持比 perfork 高的并发），并发过大会榨干服务器资源。

Nginx: 采用单线程来异步非阻塞处理请求（管理员可以配置 Nginx 主进程的工作进程的数量）(epoll)，不会为每个请求分配 cpu 和内存资源，节省了大量资源，同时也减少了大量的 CPU 的上下文切换。所以才使得 Nginx 支持更高的并发。

> Netty、Redis 基本采用相同思路。

## 什么是动态资源、静态资源分离？

动态资源、静态资源分离，是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后我们就可以根据静态资源的特点将其做缓存操作，这就是网站静态化处理的核心思路。

动态资源、静态资源分离简单的概括是：动态文件与静态文件的分离。

? **为什么要做动、静分离？**

在我们的软件开发中，有些请求是需要后台处理的（如：`.jsp`,`.do` 等等），有些请求是不需要经过后台处理的（如：css、html、jpg、js 等等文件），这些不需要经过后台处理的文件称为静态文件，否则动态文件。

因此我们后台处理忽略静态文件。这会有人又说那我后台忽略静态文件不就完了吗？当然这是可以的，但是这样后台的请求次数就明显增多了。在我们对资源的响应速度有要求的时候，我们应该使用这种动静分离的策略去解决动、静分离将网站静态资源（HTML，JavaScript，CSS，img等文件）与后台应用分开部署，提高用户访问静态代码的速度，降低对后台应用访问

这里我们将静态资源放到 Nginx 中，动态资源转发到 Tomcat 服务器中去。

? 当然，因为现在七牛、阿里云等 CDN 服务已经很成熟，主流的做法，是把静态资源缓存到 CDN 服务中，从而提升访问速度。

- 相比本地的 Nginx 来说，CDN 服务器由于在国内有更多的节点，可以实现用户的就近访问。
- 并且，CDN 服务可以提供更大的带宽，不像我们自己的应用服务，提供的带宽是有限的。

? **什么叫 CDN 服务？**

CDN ，即内容分发网络。

其目的是，通过在现有的 Internet中 增加一层新的网络架构，将网站的内容发布到最接近用户的网络边缘，使用户可就近取得所需的内容，提高用户访问网站的速度。

一般来说，因为现在 CDN 服务比较大众，所以基本所有公司都会使用 CDN 服务。

## Nginx 有哪些负载均衡策略？

负载均衡，即是代理服务器将接收的请求均衡的分发到各服务器中。

Nginx 默认提供了 3 种负载均衡策略：

- 1、轮询（默认）round_robin

  > 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 down 掉，能自动剔除。

- 2、IP 哈希 ip_hash

  > 每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决 session 共享的问题。
  >
  > 当然，实际场景下，一般不考虑使用 ip_hash 解决 session 共享。

- 3、最少连接 least_conn

  > 下一个请求将被分派到活动连接数量最少的服务器

通过 Nginx 插件，我们还可以引入 fair、url_hash 等负载均衡策略。

另外，我们还可以配置每一个后端节点在负载均衡时的其它配置：

```
weight=1; # (weight 默认为1.weight越大，负载的权重就越大)
down; # (down 表示单前的server暂时不参与负载)
backup; # (其它所有的非backup机器down或者忙的时候，请求backup机器)
max_fails=1; # 允许请求失败的次数默认为 1 。当超过最大次数时，返回 proxy_next_upstream 模块定义的错误
fail_timeout=30; # max_fails 次失败后，暂停的时间

123456
```

## Nginx 如何实现后端服务的健康检查？

- 方式一，利用 nginx 自带模块 ngx_http_proxy_module 和 ngx_http_upstream_module 对后端节点做健康检查。

- 方式二，利用 nginx_upstream_check_module 模块对后端节点做健康检查。

  > 推荐使用。

## Nginx 如何开启压缩？

开启nginx gzip压缩后，网页、css、js等静态资源的大小会大大的减少，从而可以节约大量的带宽，提高传输效率，给用户快的体验。虽然会消耗cpu资源，但是为了给用户更好的体验是值得的。

**开启的配置如下：**

将以上**配置放到nginx.conf的http{ … }节点中**。保存并重启nginx，刷新页面（为了避免缓存，请强制刷新）就能看到效果了。以谷歌浏览器为例，通过F12看请求的响应头部，如下图：

![gzip压缩效果](https://www.daixiaorui.com/upload/image/201707/1499529636761951.jpg)

**gzip压缩前后效果对比：jquery原大小90kb，压缩后只有30kb。**

gzip虽然好用，但是一下类型的资源不建议启用。

**1、图片类型**

原因：图片如jpg、png本身就会有压缩，所以就算开启gzip后，压缩前和压缩后大小没有多大区别，所以开启了反而会白白的浪费资源。（Tips：可以试试将一张jpg图片压缩为zip，观察大小并没有多大的变化。虽然zip和gzip算法不一样，但是可以看出压缩图片的价值并不大）

**2、大文件**

原因：会消耗大量的cpu资源，且不一定有明显的效果。

------

### 抱佛脚面试题

## 请解释`ngx_http_upstream_module`的作用是什么?

`ngx_http_upstream_module`用于定义可通过`fastcgi`传递、`proxy`传递、`uwsgi`传递、`memcached`传递和scgi传递指令来引用的服务器组。

## 请解释什么是`C10K`问题?

`C10K`问题是指无法同时处理大量客户端(10,000)的网络套接字。

## 解释`Nginx`是否支持将请求压缩到上游?

您可以使用`Nginx`模块`gunzip`将请求压缩到上游。`gunzip`模块是一个过滤器，它可以对不支持“gzip”编码方法的客户机或服务器使用“内容编码:gzip”来解压缩响应。

解释如何在`Nginx`中获得当前的时间?

要获得Nginx的当前时间，必须使用`SSI`模块、`$date_gmt`和`$date_local`的变量。

`Proxy_set_header` `THE-TIME $date_gmt`;

## 用`Nginx`服务器解释`-s`的目的是什么?

用于运行`Nginx -s`参数的可执行文件。

## 解释如何在`Nginx`服务器上添加模块?

在编译过程中，必须选择`Nginx`模块，因为`Nginx`不支持模块的运行时间选择。

#### **nginx状态码**

499：服务端处理时间过长，客户端主动关闭了连接。

#### **502错误可能原因**

(1).FastCGI进程是否已经启动
(2).FastCGI worker进程数是否不够
(3).FastCGI执行时间过长
fastcgi_connect_timeout 300;
fastcgi_send_timeout 300;
fastcgi_read_timeout 300;
(4).FastCGI Buffer不够
nginx和apache一样，有前端缓冲限制，可以调整缓冲参数
fastcgi_buffer_size 32k;
fastcgi_buffers 8 32k;
(5). Proxy Buffer不够
如果你用了Proxying，调整
proxy_buffer_size 16k;
proxy_buffers 4 16k;
(6).php脚本执行时间过长

将php-fpm.conf的0s的0s改成一个时间

#### nignx配置

```nginx
worker_processes  8;     工作进程个数

worker_connections  65535;  每个工作进程能并发处理（发起）的最大连接数（包含所有连接数）

error_log         /data/logs/nginx/error.log;  错误日志打印地址

access_log      /data/logs/nginx/access.log  进入日志打印地址

log_format  main  'remote_addr"request" ''status upstream_addr "$request_time"'; 进入日志格式

fastcgi_connect_timeout=300; #连接到后端fastcgi超时时间

fastcgi_send_timeout=300; #向fastcgi请求超时时间(这个指定值已经完成两次握手后向fastcgi传送请求的超时时间)

fastcgi_rend_timeout=300; #接收fastcgi应答超时时间，同理也是2次握手后

fastcgi_buffer_size=64k; #读取fastcgi应答第一部分需要多大缓冲区，该值表示使用1个64kb的缓冲区读取应答第一部分(应答头),可以设置为fastcgi_buffers选项缓冲区大小

fastcgi_buffers 4 64k;#指定本地需要多少和多大的缓冲区来缓冲fastcgi应答请求，假设一个php或java脚本所产生页面大小为256kb,那么会为其分配4个64kb的缓冲来缓存

fastcgi_cache TEST;#开启fastcgi缓存并为其指定为TEST名称，降低cpu负载,防止502错误发生

listen       80;                                            监听端口

server_name  rrc.test.jiedaibao.com;       允许域名

root  /data/release/rrc/web;                    项目根目录

index  index.php index.html index.htm;  访问根文件

123456789101112131415161718192021222324252627282930
```

参考地址：
Nginx+FastCGI运行原理 <https://blog.csdn.net/a303549861/article/details/88672889>
CGI和动态请求是什么 <https://blog.csdn.net/a303549861/article/details/88672870>





<https://www.cnblogs.com/fanBlog/p/10936190.html>

# [什么是负载均衡？](https://www.cnblogs.com/fanBlog/p/10936190.html)



**1.什么是负载均衡**

Load balancing，即负载均衡，是一种计算机技术，用来在多个计算机（计算机集群）、网络连接、CPU、磁盘驱动器或其他资源中分配负载，以达到最优化资源使用、最大化吞吐率、最小化响应时间、同时避免过载的目的。

**2.为什么需要负载均衡** 

我们在日常生活中经常免不了要去一些比较拥挤的地方，比如地铁站、火车站、电影院、银行等。无论是买票，还是排队入场，这些场所一般都会设置多个服务点或者入口的。如果没有人引导的话，大多数情况下，最近的入口会挤满人。而哪些距离较远的服务点或者入口就宽松很多。

![img](https://img2018.cnblogs.com/blog/573911/201905/573911-20190528134421557-1708431773.png)

 这种情况下，就会大大浪费资源，因为如果可以把这些排队的人很好的分散到各个入口的话会大大缩短排队时间。其实，网站的建设也是一样的。为了提升网站的服务能力，很多网站采用集群部署，就像话剧院有多个入口一样。这时候，就需要一个协调者，来均衡的分配这些用户的请求，可以让用户的可以均匀的分派到不同的服务器上。

![img](https://img2018.cnblogs.com/blog/573911/201905/573911-20190528134959589-667713517.png)

 （图挺丑的，但是不想在画图上浪费太多时间~~）

### 什么是负载均衡


在早高峰乘地铁时候，紧挨小区的地铁口人特别多，一般会有限流，还会有个地铁工作人员D那个大喇叭在喊“着急的人员请走B口，B口人少车空”。。。

而这个地铁工作人员D就是负责负载均衡的**。**为了提升网站的各方面能力，我们一般会把多台机器组成一个集群对外提供服务。然而，我们的网站对外提供的访问入口都是一个的，比如www.taobao.com。那么当用户在浏览器输入www.taobao.com的时候如何将用户的请求分发到集群中不同的机器上呢，这就是负载均衡在做的事情。

 

￼**负载均衡（Load Balance），意思是将负载（工作任务，访问请求）进行平衡、分摊到多个操作单元（服务器，组件）上进行执行。是解决高性能，单点故障（高可用），扩展性（水平伸缩）的终极解决方案。**

**![img](https://img2018.cnblogs.com/blog/573911/201905/573911-20190528112846156-21585619.png)**

 

### 3.负载均衡分类

先看下OSI七层模型

 

**OSI是一个开放性的通信系统互连参考模型，他是一个定义得非常好的协议规范。**

OSI模型有7层结构，每层都可以有几个子层。 OSI的7层从上到下分别是 7、应用层；6、表示层；5、会话层；4、传输层；3、网络层；2、数据链路层；1、物理层；

其中高层（即7、6、5、4层）定义了应用程序的功能，下面3层（即3、2、1层）主要面向通过网络的端到端的数据流。

在这七层模型种，高层次都是依赖于低层次的。层次越高，使用起来越方便。

 ![img](https://img2018.cnblogs.com/blog/573911/201905/573911-20190528140203987-590014396.png)

计算机网络有关的概念：

> TELNET、HTTP、FTP、NFS、SMTP、DNS等属于第七层应用层的概念。
>
> TCP、UDP、SPX等属于第四层传输层的概念。
>
> IP、IPX等属于第三层网络层的概念。
>
> ATM、FDDI等属于第二层数据链路层的概念。

了解了网络协议的七层模型以后，再来看看负载均衡。我们可以很明确的一点是，**负载均衡是要在网络传输中做文章的**。而要在网络传输过程搞事情，那么这七层模型就势必躲不开。

所以，根据负载均衡技术实现在OSI七层模型的不同层次，是可以给负载均衡分类的。

常见的实现方式中，主要可以在应用层、传输层、网络层和数据传输层做文章。所以，工作在应用层的负载均衡，我们通常称之为七层负载均衡、工作在传输层的我们称之为四层负载均衡。

大致可以分为以下几种，其中最常用的是四层和七层负载均衡：

**二层负载均衡** 

负载均衡服务器对外依然提供一个VIP（虚IP），集群中不同的机器采用相同IP地址，但是机器的MAC地址不一样。当负载均衡服务器接受到请求之后，通过改写报文的目标MAC地址的方式将请求转发到目标机器实现负载均衡。

**三层负载均衡**

和二层负载均衡类似，负载均衡服务器对外依然提供一个VIP（虚IP），但是集群中不同的机器采用不同的IP地址。当负载均衡服务器接受到请求之后，根据不同的负载均衡算法，通过IP将请求转发至不同的真实服务器。

**四层负载均衡** 

四层负载均衡工作在OSI模型的传输层，由于在传输层，只有TCP/UDP协议，这两种协议中除了包含源IP、目标IP以外，还包含源端口号及目的端口号。四层负载均衡服务器在接受到客户端请求后，以后通过修改数据包的地址信息（IP+端口号）将流量转发到应用服务器。

**七层负载均衡** 

七层负载均衡工作在OSI模型的应用层，应用层协议较多，常用http、radius、dns等。七层负载就可以基于这些协议来负载。这些应用层协议中会包含很多有意义的内容。比如同一个Web服务器的负载均衡，除了根据IP加端口进行负载外，还可根据七层的URL、浏览器类别、语言来决定是否要进行负载均衡。 

### 负载均衡工具

市面上有很多开源的负载均衡的工具或软件，基本都是基于前面提到的方案实现的，大多数是工作在第七层和第四层的。Nginx/LVS/HAProxy是目前使用最广泛的三种负载均衡软件。

**LVS** ：**LVS主要用来做四层负载均衡**

LVS（Linux Virtual Server），也就是Linux虚拟服务器, 是一个由章文嵩博士发起的自由软件项目。使用LVS技术要达到的目标是：通过LVS提供的负载均衡技术和Linux操作系统实现一个高性能、高可用的服务器群集，它具有良好可靠性、可扩展性和可操作性。从而以低廉的成本实现最优的服务性能。

**Nginx** ：**Nginx主要用来做七层负载均衡**

Nginx（发音同engine x）是一个网页服务器，它能反向代理HTTP, HTTPS, SMTP, POP3, IMAP的协议链接，以及一个负载均衡器和一个HTTP缓存。**。**

**HAProxy** ：**HAProxy主要用来做七层负载均衡**

HAProxy是一个使用C语言编写的自由及开放源代码软件，其提供高可用性、负载均衡，以及基于TCP和HTTP的应用程序代理。

 

**4.负载均衡算法**

负载均衡服务器在决定将请求转发到具体哪台真实服务器的时候，是通过负载均衡算法来实现的。负载均衡算法，是一个负载均衡服务器的核心。

就像电影院门口的引导员一样，他根据什么把排队人员分配到具体的入口呢？是哪个入口人少吗？还是哪个入口速度最快？还是哪个入口最近呢？

负载均衡算法可以分为两类：静态负载均衡算法和动态负载均衡算法。

1）.静态负载均衡算法包括：轮询，比率，优先权

- **轮询（Round Robin）：**顺序循环将请求一次顺序循环地连接每个服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从顺序循环队列中拿出，不参加下一次的轮询，直到其恢复正常。
- **比率（Ratio）：**给每个服务器分配一个加权值为比例，根椐这个比例，把用户的请求分配到每个服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配, 直到其恢复正常。
- **优先权（Priority）：**给所有服务器分组,给每个组定义优先权，BIG-IP 用户的请求，分配给优先级最高的服务器组（在同一组内，采用轮询或比率算法，分配用户的请求）；当最高优先级中所有服务器出现故障，BIG-IP 才将请求送给次优先级的服务器组。这种方式，实际为用户提供一种热备份的方式。

2).动态负载均衡算法包括: 最少连接数,最快响应速度，观察方法，预测法，动态性能分配，动态服务器补充，服务质量，服务类型，规则模式。

- **最少的连接方式（Least Connection）：**传递新的连接给那些进行最少连接处理的服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配, 直到其恢复正常。
- **最快模式（Fastest）：**传递连接给那些响应最快的服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。
- **观察模式（Observed）：**连接数目和响应时间以这两项的最佳平衡为依据为新的请求选择服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。
- **预测模式（Predictive）：**BIG-IP利用收集到的服务器当前的性能指标，进行预测分析，选择一台服务器在下一个时间片内，其性能将达到最佳的服务器相应用户的请求。(被BIG-IP 进行检测)
- **动态性能分配(Dynamic Ratio-APM)：**BIG-IP 收集到的应用程序和应用服务器的各项性能参数，动态调整流量分配。
- **动态服务器补充(Dynamic Server Act.)：**当主服务器群中因故障导致数量减少时，动态地将备份服务器补充至主服务器群。
- **服务质量(QoS）：**按不同的优先级对数据流进行分配。
- **服务类型(ToS)：**按不同的服务类型（在Type of Field中标识）负载均衡对数据流进行分配。
- **规则模式：**针对不同的数据流设置导向规则，用户可自行。

以上，就是目前实现负载均衡的主流算法。不同的负载均衡服务器会选择不同的算法。就像电影院和火车站可能会选用不同的引导策略一样。火车站可能会把行李少的旅客分配到一个专门的入口，可能给即将发车的旅客分派到特快入口，手持可扫描车票的用户单独分配到特殊入口等。 